%\section{Computing Continuum}
%\label{sec:example}
%
%%Herein we will discuss the challenges of developing a mobile application that exploits the computing continuum, as well as present a running example that will be used throughout the rest of the paper to exemplify our work.
%
%As previously stated, the continuum enables the convergence of many heterogeneous infrastructures, from cloud-hosted virtual machines down to mobile devices. Given that the two fundamental elements of computation are data and behavior, the first major challenge of developing an application that exploits the computing continuum consists in \emph{deciding where in the continuum the data and the behavior should be deployed}. This decision needs to be informed by the profound heterogeneity that exists between the different infrastructures that constitute the continuum. 
%
%Amongst other things one must take into account important QoS aspects, such as availability and latency, as discussed in Section~\ref{sec:intro}. Let us focus, for example, on a continuum that comprises a cloud-based solution, an edge-based infrastructure, and a mobile device. Data and behavior that are deployed to cloud solutions will benefit from high availability, at the cost of introducing higher latency; while data and behavior deployed to an edge-based infrastructure will benefit from a much lower latency, at the cost of having a lower availability as well. A third possibility would be to deploy the data and the behavior exclusively to the mobile device; however, this could lead to important battery drains (see Section~\ref{sec:evaluation}), not to mention other limitations. Balancing these trade-offs at design time can be difficult. The challenge is, therefore, to allow applications to dynamically, and opportunistically, decide where the data and the behavior should be deployed and executed. 
%
%If we focus on behavior, it is common to distinguish between stateful and stateless computation. The main distinguishing factor between stateful and stateless components is that the latter do not produce side-effects, and that their outputs depend solely on their inputs. If we focus on data, it is common to distinguish between mutable and immutable data. While mutable data can be modified after its creation, the same is not true for immutable data. In components that adopt immutable data, the data is initialized once and for all at deployment time.
%
%As we shall discuss in Section~\ref{sec:proposal}, it is our view that the computing continuum should focus on stateless computation with immutable data. Stateless computation with immutable data is much easier to replicate (and test) across the continuum, since no data synchronization is required and any data needed by the computation can be obtained at deployment time. Nevertheless, stateful computation and mutable data cannot always be excluded entirely from modern applications. For these cases we envision a mixed solution in which traditional cloud-based resources are adopted alongside the continuum. 
%
%Developing applications in the computing continuum also poses other important challenges. For example, when selecting where a certain computation should be achieved, we need to take into account important \emph{security} aspects, such as \emph{authorization}, \emph{confidentiality}, and \emph{integrity}. Also, deployment and execution in the continuum will need \emph{tool} support, e.g., for performing \emph{integration tests}, \emph{runtime monitoring and adaptation}, etc. 
%
%Although these challenges are interesting, and important research endeavors in themselves, in this paper we focus on establishing the basis upon which the computing continuum can develop. In particular, we focus on achieving (i) the dynamic and automatic deployment of computation by part of the infrastructures that constitute the continuum, and (ii) the opportunistic selection of where to execute the computation.

%END OF PREVIOUS CONTINUUM

%REVISED CONTINUUM

\section{The Continuum}\label{sec:continuum}
%
%\begin{figure}[tbp]
%	\includegraphics[width=1\textwidth]{figs/A3-E-model.pdf}
%	\caption{The Continuum Model.}
%	\label{fig:Continuum-model}
%\end{figure}

%The \textit{Continuum model}, depicted in Figure~\ref{fig:Continuum-model}, defines the actors and mechanisms involved in the realization of the mobile-edge-cloud continuum.

%Domain formalization
%Application Requirements
%Service SLA
%Service Life-cycle

\subsection{Infrastructure Model}

%Although the continuum can hypothetically support any number of heterogeneous infrastructures, this paper focuses on three domains. The \texttt{mobile domain} is deployed to the client's mobile device, and provides local stateless computation (while enabling device-to-device collaboration through distributed mobile domains --i.e., by allowing a client to call a microservice deployed on another mobile device-- is surely interesting, for now we consider it part of our future work). The \texttt{edge domains} refer to edge-based infrastructure that can be deployed to a local server (local-edge domain) or to cellular stations (mobile-edge domain). Finally, the \texttt{cloud domain} refers to a cloud-based solution such to AWS Lambda.

%The continuum is composed of computational resources from cloud, edge, and mobile computing devices. 
%
%Cloud datacenters count with virtually unlimited computational resources needed to cope with the aggregated demand from a wide coverage area. Edge nodes~\cite{}, in contrast, are limited in computational resources, but cover a much narrower area with lower aggregated demand. 
%
%Cloud datacenters are reachable through multiple hops of network, including the Internet backbone. Edge nodes, in turn, are ideally placed a few hops away from clients to minimize network latency and jitter. 

%TODO [Martin] I've slightly changed this and next paragraph to be compliant with the ETSI standard
In our formulation, edge nodes are distinguished by the networking technology they use: \textit{mobile edge} hosts (in the context of Multi-Access Edge Computing or MEC~\cite{etsimec16}) integrate with cellular network infrastructure (e.g., a 5G base station), whereas \textit{local edge} hosts integrate with local area network infrastructure (e.g., an access point). Also, we assume that cloud and edge providers may be different from one another (e.g., Amazon AWS and telecom operators providing MEC) and that coordination among hosts (e.g., at different base stations) may not always be feasible.


% and unable to coordinate the allocation of resources.

%Later on, this heterogeneity is addressed with variations of the proposed service life-cycle management.

In the continuum, mobile devices play two roles: they are both clients and providers of computational resources. The motivation for including the mobile device's own resources in the model is threefold: (i) the substantial increase in computational capacity exhibited by modern devices; (ii) the compatibility of these devices with the computation of continuum microservices (see Section~\ref{sec:application_model}); and (iii) to give applications a zero network latency and highly available alternative.% to cloud and edge providers. 


%Figure X~\ref{fig:topology} illustrates a topology composed of cloud, mobile-edge, local-edge, and mobile \textit{domains}. 
Throughout this paper, we refer to \textit{cloud}, \textit{edge}, and \textit{mobile} \textit{domains}. 
%Each part of the continuum topology (cloud, mobile-edge, local-edge, and mobile) is composed of domains.
A domain yields a common  abstraction for the heterogeneous 
%compute, storage and network 
resources that make up the continuum topology, e.g., server(s), virtual machine(s), container(s), CPU, memory, storage, and network components. In the particular case of MEC, the term \textit{domain} extends the one provided by ETSI for a \textit{mobile edge host}~\cite{etsimec16,etsimec16:03}.



%constituents of the continuum. Indeed, it hides the fact that they make use of heterogeneous \textit{computational resources} (e.g., server(s), virtual machine(s), container(s), memory, CPU, storage, etc.) and networking infrastructures (e.g., access points, radio access networks, etc.). 

%Examples of A3-E domains are \textit{cloud domains}, i.e., cloud-based FaaS platforms covering a specific geographical region (e.g., AWS Lambda\footnote{\url{https://aws.amazon.com/lambda}} in Europe); \textit{edge domains}, representing local-edge (e.g., domestic servers or within an office building) and mobile-edge sites (e.g., servers at cellular base stations~\cite{beck2014mobile}); and \textit{mobile domain} representing a client device's own resources.

%TODO


%Whilst cloud and edge resources are shared among different applications and managed by cloud/edge providers, mobile device resources are exclusively employed by local applications. 

\subsection{Application Model}\label{sec:application_model}

\begin{figure}[tbp]
	\includegraphics[width=0.85\textwidth]{figs/Continuum-arch}
	\setlength{\belowcaptionskip}{-10pt}
	\caption{The high level architecture of a mobile application exploiting both the computing continuum -- by means of $\mu$-services ($\mu$S) provided by mobile, edge, and cloud domains -- and conventional mobile/cloud computing -- by means of local computation and cloud services (CS).}
	\label{fig:Continuum-arch}
\end{figure}

%On top of the physical model, 

We propose an \textit{application model} in which stateless components and immutable data form \textit{continuum services}, which are dynamically deployed to mobile, edge, and cloud resources; stateful components, which may still be needed in an application, are deployed to cloud data centers or to the client's own device, depending on a design-time decision. 

%This choice prevents 
The proposed model prevents data consistency problems (and the corresponding complexity of potential solutions) that would arise if stateful components such as databases were deployed to finely distributed edge nodes. It also allows multiple service instances to coexist along the continuum. Moreover, service instances may be deployed and undeployed independently without the need for state migration, favoring the seamlessly transition from one service provider to the other. The latter is particularly important to cope with client mobility.% and the unpredictible fluctuations in service demand. 

Continuum services provide a common model that is used regardless of the domain; even mobile domains expose functionality by means of a well-known service-based interface. 
%A priori, continuum $\mu$-services are portable, unless they require capabilities that cannot be met by specific domains. 
Moreover, continuum services can be defined as \textit{microservices}\footnote{Hereafter referred as $\mu$-service.}~\cite{lewis2014microservices}, as they are small, modular, communicate with lightweight mechanisms (often through an HTTP RESTful API) and are independently deployable by fully automated machinery. Accordingly, continuum $\mu$-services consist of a set of artifacts that fulfill a given functionality. In particular, these artifacts can refer to: (i) stateless function(s); (ii) immutable data (e.g., a trained neural network model); and (iii) other dependencies (e.g., software libraries). 

Continuum $\mu$-services are aligned with the \textit{Function-as-a-Service} (FaaS) execution model~\cite{MateosFaaster17}. FaaS has been proposed as an alternative cloud paradigm in which business functionality\footnote{Note that our approach targets \textit{application-level functions}, whereas Virtualized Network Functions (VNFs~\cite{etsimec16}) are considered as a part of the underlying infrastructure.} is provided without pre-allocating computational resources. Instead, shared resources (e.g. containers) are used to provision and execute functions on demand, in only a few milliseconds. 



%Continuum $\mu$-services provides a common model that is used regardless of the domain; even mobile domains expose functionality by means of a well-known service-based interface. A priori, continuum $\mu$-services are portable, unless they require capabilities that cannot be met by specific domains.





%This requires to support FaaS not only at cloud level, but also to bring it to (mobile) edge platforms~\cite{etsimec16}. 

%As state is a fundamental aspect of many applications, we propose that mobile devices and, for most cases, cloud datacenters should remain responsible for stateful components such as persistence.  

%This decision is also aligned with the limitations in computational resources of edge nodes. %Indeed, the deployment of components like databases to the edge would be unrealistic for large scale applications.


Figure~\ref{fig:Continuum-arch} illustrates the architecture overview of a continuum application. The client-side application comprises \texttt{client-side logic}, \textit{local persistence}, and \texttt{user interface} components, whereas the cloud infrastructure comprises \texttt{server-side logic} and \texttt{persistence} components. Continuum $\mu$-services are responsible for stateless computation and are opportunistically deployed to different domains.

\subsection{Life-cycle Management}\label{sec:challenges}

% [Danilo] It's been really hard to change the formulation without falling in the trap of not been objective. For me, Awareness is mostly about letting domains to know *when* to allocate resources and to let clients to know *which* domains can be chosen. Please let me know if you have insights about it. For sure I agree to make the formal part easier to digest, but it wouldn't change the focus on allocation/placement. 

When managing the life-cycles of continuum services there are two conflicting goals: i) the satisfaction of application requirements and ii) the optimization of the resources consumed by these applications. In this paper we focus in three kinds of application requirements: service latency, battery consumption, and availability; simultaneously, we target the efficient and scalable usage of computational resources --- namely CPU, memory, and storage --- from cloud and edge providers.

In the continuum, a plethora of disjoint cloud and edge domains can host the execution of $\mu$-services, i.e., they must be able to handle operational aspects such as \textit{downloading and installing} the $\mu$-services. Also, mobile clients will freely enter and exit geographical areas that are covered by distinct edge domains; even cloud domains may see considerable variations to their aggregate demand over time. In such a scenario it may be unfeasible to predict the origin and intensity of the demand that the different $\mu$-services at each domain might see. 

From the provider's perspective, an efficient and scalable allocation of its (virtualized) resources 
%corresponds to the minimum number of $\mu$-service instances that 
must be allocated by each of its domains to cope with the maximum accepted latency of each provided $\mu$-service. To be efficient, the allocation of resources should be able to mimic the corresponding fluctuations of demand, i.e., be highly responsive. Consequently, it is important that the mechanisms governing resource allocation in each domain be \textit{aware} of the actual, and potential, demand for each provided $\mu$-service.

To better express this problem, let's consider the set of $\mu$-services $S = \{s_j \mid j = 0,1,...,J\}$.
%In turn, $F_i = \{f_{i,j}\}_j$ defines the set of instances of $s_i$, with $0 \le j \le n_i$.
%Instances for each $\mu$-service are defined by the set $F_i = \{f_{i,j}\}_j$, with $0 \le j \le n_i$.
Vector $\bar{c} = (c_1, ..., c_J)$ holds the number of instances for all $\mu$-services. Each instance is bound to a container; resources allocated to each container 
%Each $s_j \in S$ has a corresponding set of instances $F_j = \{f_{j,i} \mid i = 0,1,...,I_j\}$, where each instance is bound to a container. 
(e.g., CPU and memory) are considered fixed and equal for all $\mu$-services, coherently to the architecture of FaaS frameworks such as OpenWhisk~\cite{OpenWhisk}.

Now let's assume that each provided $\mu$-service $s_i \in S$ is bound to an SLA specifying its \textit{maximum accepted service latency} $\Delta_j$ 
as well as the minimum/maximum number of service instances $Kmin_{j}/Kmax_{j}$. %, and a relative priority $p_i$. 
Given the fluctuations in the workload and the response time $\tau_j$ (comprising both \textit{setup time} and \textit{service time}) of each $\mu$-service $s_j \in S$, the aim of a \textit{domain manager} is to find the minimum $c_j$ for each $\mu$-service so that, $\forall s_j \in S,\ \tau_j \le \Delta_j\ \wedge\ Kmin_j \le c_j \le Kmax_j$. 

% (e.g., maximum service latency, simultaneous request threshold, etc). 


%Even if emerging network technologies could be employed to route traffic from one base station to the other, continuum $\mu$-services implemented after the FaaS model are ephemeral (they may even last for only one invocation), stateless, and scaled as needed~\cite{Roberts:2016}. 

%In FaaS, functions are ephemeral (they may even last for only one invocation), stateless, and scaled as needed~\cite{Roberts:2016}. 

%To better express this problem, let's consider the set of $\mu$-services $S = \{s_j \mid j = 0,1,...,J\}$.
%%In turn, $F_i = \{f_{i,j}\}_j$ defines the set of instances of $s_i$, with $0 \le j \le n_i$.
%%Instances for each $\mu$-service are defined by the set $F_i = \{f_{i,j}\}_j$, with $0 \le j \le n_i$.
%Vector $\bar{c} = (c_1, ..., c_J)$ holds the number of instances for all $\mu$-services. Each instance is bound to a container; resources allocated to each container 
%%Each $s_j \in S$ has a corresponding set of instances $F_j = \{f_{j,i} \mid i = 0,1,...,I_j\}$, where each instance is bound to a container. 
%(e.g., CPU and memory) are considered fixed and equal for all $\mu$-services, coherently to the architecture of FaaS frameworks such as OpenWhisk~\cite{OpenWhisk}.
%
%Now let's consider that each provided $\mu$-service $s_i \in S$ is bound to an SLA specifying its maximum accepted response time $\Delta_j$, which comprises both queue time (if any) and service time; and to the minimum/maximum number of service instances $Kmin_{j}/Kmax_{j}$. %, and a relative priority $p_i$. 
%Given the fluctuations in the workload and the \textit{actual} response time $\tau_j$ of each $\mu$-service $s_j \in S$, the aim of a \textit{domain manager} is to assure that, $\forall s_j \in S,\ \tau_j \le \Delta_j$, provided that $Kmin_j \le c_j \le Kmax_j$. 



%Also, each instance $f_{ij} \in F_i$ is bound to a single core container with fixed memory and storage. Considering that CPU is a scarcer resource, we may assume, without loss of generality, that the number of $\mu$-instances per domain is limited by the amount of CPU cores available ($|C|$) in its pool of resources, i.e., that $\sum_{i=1}^{m} k_i \le |C|$.

%Furthermore, as the demand for different services is expected to change over time, unless $\forall S_i \in S, U_i = U_i$, idle resources may be employed to reduce $\delta_i$ according to $P_i$.

From the client's viewpoint, the challenges for the materialization of the continuum are mainly twofold: i) domains may need to be dynamically discovered; ii) the client may need to choose, at run time, among different domains that provide similar $\mu$-services with different QoS. 

For a continuum application, an optimal domain selection is the one that, given a set of requirements (e.g., maximum accepted latency, battery consumption), and the perceived QoS of different services (e.g., availability, service latency), satisfies the multi-attribute decision of which provider to be employed for each service. Moreover, since continuum $\mu$-services are modular and independently deployed, it consists of individual decisions regarding each $\mu$-service consumed by the application.

To better express the client-side Allocation goal, let's extend the previous formulation by considering a continuum application $C_a$ that relies on the set of $\mu$-services $S_a = \{s_{a,i} \mid i = 1,2,...,I_a\}$, and the set of disjoint continuum domains $D = \{d_p \mid p = 1,2,...,P\}$ perceived by the client.
%, including the mobile domain. 
Each domain $d_{p} \in D$ provides a set of $\mu$-services $S_{p} = \{s_{p,j} \mid j =  1,2,..., J_p\}$. For each $s_{a,i} \in S_a$, there is at least one domain providing that $\mu$-service, that is, $\forall s_{a,i} \in S_a, \exists\ s_{p,j} \in \bigcup_{p=1}^{P} S_p \wedge s_{p,j} = s_{a,i}$. 

Now let's consider that each $s_{a,i} \in S_a$ is bound to a set of QoS requirements $QoS_a = \{q_{a,u} \mid u = 0, 1, ..., U_a\}$ and that each $q_{a,u} \in QoS_a$ is represented by a tuple $(ct_{a,u}, w_{a,u})$ respectively defining a \textit{constraint} (e.g. $service\ latency \le 300ms$) and a \textit{weight} for that attribute, with $w_u \in 0 \le w_u \le 1 \wedge w_u \in \mathbb{R}$. For each $q_{a,u} \in QoS_a$, $actual_{p,a,u}$ defines the \textit{value} for that QoS attribute as perceived by the client. It follows that, for each $s_{a,i} \in S_a$, the aim of the \textit{mobile middleware} is to select the domain $d_p \in D$ 
%best satisfying the set of attributes in $QoS_o$, i.e., 
that maximizes the utility function $U_a(p) = \sum_{u=1}^{U_a} w_{a,u} * actual_{p,a,u}$, provided that $\forall q_{a,u} \in QoS_a, actual_{p,a,u} \vdash ct_{a,u}$, i.e., that QoS constraints are satisfied.

%service latency and cost as our requirements. From the client viewpoint, latency can be refined into network and service latency, with cloud providers exhibiting highest network latency and lowest service latency due to more powerful computational power; edge providers exhibiting low network latency and higher service latency; and finally the local mobile environment exhibiting zero network latency and the highest service latency due to more limited computational power. Service cost, in turn, is lower in the cloud than in the edge and null in the mobile environment. Given the relative importance of each attribute, the aim of the provider selection is to 


%The life-cycle management is therefore dual: it comprises the provider-side allocation of service instances at each domain; and it also encompasses the client-side decision of which domain must be selected for each continuum $\mu$-service.

\subsection{Running Example}
\label{sub:example}

%\begin{figure}[tbp]
%	\includegraphics[width=0.7\textwidth]{figs/Continuum-Scenario}
%	\setlength{\belowcaptionskip}{-10pt}
%	\caption{Heterogeneous applications such as Augmented Reality and Mobile Games (MG) rely on $\mu$-services deployed along the compute continuum (mobile, mobile-edge, local-edge, and cloud).}
%	\label{fig:continuum-scenario}
%\end{figure}

%Figure~\ref{fig:continuum-scenario} shows a complete example scenario involving different applications that rely on computation executed in the cloud, edge, or in the user's own devices.

We illustrate the continuum with an example scenario that involves multiple applications that rely on computation executed in the cloud, edge, and/or in the user's own device.

First, let us consider an Augmented Reality (AR)~\cite{GarrigaMendonca2017} application, employed by our user to explore the points of interest (POI) in the city she is currently visiting. This real-time application involves heavyweight image processing for the \textit{extraction of features} from the captured scenes, as well as a trained neural network model to \textit{match features} from an extensive object catalog. 

This is a compute intensive and a latency-sensitive kind of application; as such the AR can definitely benefit from adopting the continuum~\cite{beck2014mobile}. Indeed, despite the capacity of mobile devices, with these kinds of applications it is common for users to experience functional and non-functional degradation (e.g., reduced object catalog, battery drain, etc). By offloading the extraction and matching tasks to a server, the user can enjoy an improved Quality-of-Experience.

Two continuum $\mu$-services are modeled for this application: one relies on an image processing library and a trained model, the other on a feature-based object catalog. Client-side logic is only responsible for capturing scenes from the device's camera and for updating the scene rendered by the display.

%avoid recharging her glasses and improve productivity. 

To support this application, mobile-edge servers have been deployed to the base stations covering touristic areas. Their additional storage allows a larger set of objects to be recognized, thanks to a more completely trained model. Variations in the workload are handled with a fast instantiation of AR $\mu$-services, which must consider other applications that may be relying on the same servers.

%In contrast, the network latency to cloud servers may be prohibitive for this real-time application. The decision of which continuum provider to employ must be informed by the application requirements and the Quality-of-Service (QoS) of each alternative. 

After her tour, our user calls for an autonomous vehicle (AV) to drive her back to her hotel. During the drive back, she starts editing the pictures taken during the day; this activity is only interrupted by notifications from the AR application providing nearby POI information. 

To reduce the processing time and avoid battery drain, the AV features a local-edge server that provides a catalog of $\mu$-services for image processing, including those needed by the AR application. The vehicle uses of a \textit{route planning} $\mu$-service
%deployed at mobile-edge servers located at cellular base stations 
%to receive updates about 
to calculate the best plan to reach our user's destination. Since latency is not a main requirement, the latter is served by a cloud provider.

%Additionally, it relies on low-latency services to become aware of sudden events like accidents.

%To support the AV, two continuum $\mu$-services are envisioned: the \textit{route planning}, which relies on a traffic dataset and a routing software and can cope with higher latency, and the \textit{incident notification}, which relies on low-latency communication between vehicles and mobile-edge base stations to forward incident events received by that base-station.

%TODO: the incident notification is not consistent with our service model; either remove the AV example or find a different kind of low-latency service (e.g., augmented reality of what is seen from inside the car?)
%[Danilo] What about web sockets? Or push-notification? 

%within milliseconds the vehicle can become aware of to adjust its routes to avoid heavy traffic. In particular, let's say that a new path consists of residential streets with data services only (without mobile-edge coverage). The AV continues to fetch updates, which are now served by a cloud provider. The additional network latency is partially compensated with the low speed limit of the residential area.

%During our user's journey home, her AV passes by a touristic region. The mobile-edge domains covering this area provides continuum $\mu$-services to be consumed by an AR application for tourists. These services share computational resources with those of AVs passing by the same area, as well as any other continuum $\mu$-services that happens to be provided by those mobile-edge domains.

%Due to resource limitation, each mobile-edge domain must employ mechanisms to efficiently manage its resources and assure that competing $\mu$-services are best provided according to their Service Level Agreement (SLA). In our example, the AV's \textit{incident notification} $\mu$-services is likely to enjoy a higher priority regarding the AR's $\mu$-services due to the criticality of the former.

Once at her hotel room, our user continues to edit the images and videos that she shot during the day. Later on, she decides to enjoy a Mobile Game (MG). The MG consists of client-side logic and user interfaces, as well as complex calculations that pose a burden to her mobile device's CPU. 
%The application consists of for processing the game state, which must be passed as a parameter in conjunction with game events (e.g., user inputs). 

To support guest applications, the hotel provides a local-edge server. The server identifies the image editing application and the MG and, after having dynamically downloaded and installed the necessary software, starts providing the required $\mu$-services. %for processing the game state, which must be passed as a parameter in conjunction with game events (e.g., user inputs). 
Last but not least, conventional cloud infrastructure provide stateful services (e.g., multimedia storage, authentication, and persistence).% and persistence (e.g., player scores).  

%This latter scenario exploits different parts of the continuum. A domestic local-edge domain must identify, fetch, and deploy the corresponding $\mu$-services. Meanwhile and to assure a high availability, the mobile domain remains responsible for the provisioning of these $\mu$-services. Finally, cloud domains complement the possible alternatives for hosting the $\mu$-services and mitigating battery drain, but network latency must be taken into account.

%Traditional cloud resources are employed as a reliable alternative to edge-based computation. Similarly, local services are employed as alternatives to edge services until they have been acquired and made available by a local-edge server. Whilst the transition between mobile-edge and cloud is transparent, the use of local-edge services involves mutual client-server awareness.


%TODO [Danilo] better in proposal
%Upon installation, the local-edge server becomes aware of a new continuum-compliant application and, while the app continues to run locally on her device, it proceeds to setup the services needed to allow the application to offload some of the computation. Once the setup is complete, the application autonomously starts using the edge services with the purpose of preserving the device's resources. Not only does the game's performance improve, battery consumption is also reduced.  




