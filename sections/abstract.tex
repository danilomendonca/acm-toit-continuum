
The evolution of mobile computing and the emergence of low latency applications is challenging existing approaches for computation offloading to the cloud. Although its virtually infinite resources, the latency of sending and retrieving great amounts of data from/to the cloud is prohibitive for certain applications. In turn, devices are still too resource-constrained (mainly regarding battery and CPU) to fulfill application requirements in a timely fashion.

In this scenario, edge computing appears as a promising solution to bridge this gap, allowing cloud, edge, and mobile computing to be seen as parts of a \textit{computational continuum} serving different sorts of applications. In this paper, we propose A3-E, %(Awareness, Acquisition, Allocation and Engagement) 
a unified model for the realization of such a continuum by defining and implementing the mechanisms to place computation onto the heterogeneous parts of the continuum, accounting not only the dynamic contexts of clients and servers but also the mixed requirements of mobility, low-latency, and computation. A3-E features an automated management of offloaded functionality in the form of services, by employing and extending to the edge the paradigm of serverless computing. This achieves an efficient usage of computational resources needed for the realization of edge computing and consequently of the continuum.

Experiments have shown that A3-E is capable of dynamically manage requests of a mobile agumented-reality application, to be served by different components of the continuum (cloud, edge, mobile). In this context, latency was reduced up to 90\% when using edge services instead of cloud services, while battery consumption decreased 74\% when offloading computation from the mobile device to the edge/cloud.%, as well as showing the feasibility of A3-E in the realization of the cloud-edge-mobile continuum.

%As demonstrated through different experiments, an augmented reality application hosted by an Android platform device was able to rely on a client-side middleware implementing the A3-E process to proxy its requests to services dynamically selected from the continuum. In specific, these services were implemented as functions that were executed in a cloud-based, edge-based, and mobile-based runtimes. The experiments have shown up to 90\% reduction of latency when edge services were used instead of cloud services, and a 74\% decrease of battery consumption when computation was offloaded from the Android device to edge servers. These results corroborate the importance of edge computing, as well as the feasibility of A3-E in the realization of the cloud-edge-mobile continuum.

%In this paper, we propose a unified model for the realization of the computational continuum formed by cloud, edge, and mobile computing. At its core (and providing the name of the model) lies A3-E --- \textit{(A)wareness, (A)cquisition, (A)llocation and (E)ngagement} --- a flexible process targeting the efficient provisioning of computational resources from heterogeneous sources in the continuum to client applications featuring mixed requirements such as mobility, low-latency, and complex computation. 
%In specific, 
%What: A3-E and Serverless Computing 
%Targeting efficiency and scalability, 
%A3-E proposes an automated management of service life-cycle by employing and extending to the edge the paradigm of serverless computing~\cite{Hendrickson:2016,baldini2017serverless,GarrigaMendonca2017}. In specific, A3-E explores the function-as-a-service (FaaS) execution model~\cite{MateosFaaster17} to allow stateless functions to be autonomously and opportunistically fetched, deployed and exposed as services with the twofold objective of achieving an efficient usage of computational resources needed for the realization of edge computing and consequently of the continuum. Additionally, A3-E encompasses the mutual client-server awareness and the dynamic placement of stateless computation along the continuum.



%by bringing computation and data near to users and devices. However, the resource-finite nature of edge servers constrains the possibility of deploying full applications on them. To cope with these problems, we propose a serverless architecture at the edge, bringing a highly scalable, intelligent and cost-effective use of edge infrastructure's resources with minimal configuration and operation efforts. The feasibility of our approach is shown through an augmented reality use case for mobile devices, in which we offload computation and data intensive tasks from the devices to serverless functions at the edge, outperforming the cloud alternative up to 80\% in terms of throughput and latency.


%With the advent of Internet of Things, the evolution of mobile computing, and the emergence of real-time applications, the processing of an exponentially increasing volume of data must be performed in a timely fashion, i.e., with minimum latency. Despite the elasticity and vast computing power of existing cloud platforms, the access to these resources involves multiple hops of network communication, adding prohibitive latency to requests' processing. Such limitation has the following implications: 1) cloud services may fail to satisfy the requirements of real-time/low-latency applications; and 2) offloading of delay-sensitive computation from devices with constrained resources to cloud servers is unlikely to work due to network latency.
%What: The challenges in realizing edge computing
%To reduce network latency, data processing must be performed closer to where it is produced and consumed. In accordance with this principle, the emerging paradigm of edge computing~\cite{Shi:2016} states that computing power should be pushed from centralized datacenters to the edge of the network. 
%What: The challenges in the realization of edge computing
%The materialization of this paradigm, however, still poses many challenges:

%What: Resouce limitations of edge computing and the need for a more efficient provisioning
%What: Aways availability vs opportunistic service setup
%--- First, a finely distributed edge infrastructure~\cite{Dehos14millimeter5g} is not expected to exhibit virtually unlimited resources as cloud datacenters. This limitation imposes a more efficient allocation of edge resources. Current models based on virtualization and containerization, although successfully adopted in the cloud~\cite{zabolotnyi2015jcloudscale}, may not be feasible in the context of edge computing, as they require a minimum pre-allocation of resources. Therefore, a more efficient model is needed to deem edge computing scalable~\cite{GarrigaMendonca2017}. Also, while cloud services cover very large areas in which requests are always expected, the fine-grained coverage of edge computing implies that clients may be absent and services remain idle. Therefore, to optimize the usage of edge resources, services should be opportunistically made available.

%What: The need for taking alternative edge domains into account
%--- Second, different sorts of edge computing infrastructures may exist~\cite{1,2,Tarneberg2017}, including servers located at cellular base stations, temporarily placed nearby public events, and inside buildings and houses to provide support for smart space applications. Those integrated to local network infrastructures would require the discovery of its services on-the-fly when inside their coverage area.

%What: The continuum
%--- Finally, considering that edge computing may not always be available and taking into account the high availability of cloud computing, the former should complement rather than replace the latter. This vision also extends to computation that may opportunistically be offloaded from resource-constrained devices to nearby edge servers in order to augment their capabilities. In this sense, cloud, edge, and mobile computing should be seen as parts of a \textit{computational continuum} serving different sorts of applications. Its realization requires not only the materialization of edge computing,
%, whose particular characteristics require an \textit{efficient} management and provisioning of its resources, 
%but also the mechanisms to allow computation to be seamlessly placed onto the heterogeneous parts of the continuum according to dynamic contexts of clients and servers. % including both the context of clients and service providers.

%In this paper, we propose a unified model for the realization of the computational continuum formed by cloud, edge, and mobile computing. At its core (and providing the name of the model) lies A3-E --- \textit{(A)wareness, (A)cquisition, (A)llocation and (E)ngagement} --- a flexible process targeting the efficient provisioning of computational resources from heterogeneous sources in the continuum to client applications featuring mixed requirements such as mobility, low-latency, and complex computation. 
%In specific, 
%What: A3-E and Serverless Computing 
%Targeting efficiency and scalability, 
%A3-E proposes an automated management of service life-cycle by employing and extending to the edge the paradigm of serverless computing~\cite{Hendrickson:2016,baldini2017serverless,GarrigaMendonca2017}. In specific, A3-E explores the function-as-a-service (FaaS) execution model~\cite{MateosFaaster17} to allow stateless functions to be autonomously and opportunistically fetched, deployed and exposed as services with the twofold objective of achieving an efficient usage of computational resources needed for the realization of edge computing and consequently of the continuum. Additionally, A3-E encompasses the mutual client-server awareness and the dynamic placement of stateless computation along the continuum.

%What: The obtained results for latency and battery; other metrics?
%As demonstrated through different experiments, an augmented reality application hosted by an Android platform device was able to rely on a client-side middleware implementing the A3-E process to proxy its requests to services dynamically selected from the continuum. In specific, these services were implemented as functions that were executed in a cloud-based, edge-based, and mobile-based runtimes. The experiments have shown up to 90\% reduction of latency when edge services were used instead of cloud services, and a 74\% decrease of battery consumption when computation was offloaded from the Android device to edge servers. These results corroborate the importance of edge computing, as well as the feasibility of A3-E in the realization of the cloud-edge-mobile continuum.

