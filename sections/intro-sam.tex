\section{Introduction}
\label{sec:intro}

Mobile devices, edge-, and cloud-computing have the potential to form a \textit{computing continuum} on which new and disruptive types of applications can be built. This continuum enables the seamless convergence of heterogeneous infrastructure, stretching all the way from cloud resources to mobile devices, including intermediate steps such as ISP gateways, cellular base stations, and private cloud deployments.

The heterogeneity of the computing continuum is profound and multi-faceted. In the cloud, computing resources are typically provided through virtualization and containerization~\cite{leitner2016patterns, Quatrocchi2016discrete}, and there is an illusion of infinite resource availability thanks to horizontal scaling. In contrast, in edge computing, computational resources are scarce and must be managed very efficiently~\cite{Dehos14millimeter5g,GarrigaMendonca2017}. This is even truer for mobile devices, as they are strongly constrained by battery and other limitations. 

In the cloud, networking protocols and technologies (e.g., traffic managers, DNS, etc.) allow clients to access resources across countries and continents. Conversely, in edge computing, to access resources they must be available within the client's network coverage, be it cellular (e.g., 5G) or local (e.g., domestic or office). Of course, we can consider the computational resources of the client's mobile device to be always accessible. % as long as the battery lasts.

Finally, there are important QoS considerations that need to be made. While cloud resources can provide vast computing power through elasticity, accessing them may involve multiple hops of network communication, leading to prohibitive latency in the processing of client requests. Indeed, one of the main motivations for introducing edge computation is to mitigate the network latency~\cite{Shi:2016}, which is nullified when execution is performed locally on the client's mobile device.

The advantage of embracing the computing continuum is that it allows an application to situationally and opportunistically decide where in the continuum a specific calculation should be performed. This decision will consider the resources that are actually available in the continuum at that specific moment in time, depend on the client's geo-location and connectivity, and be informed by existing QoS requirements, e.g., maximum acceptable latency~\cite{GuptaIfogSim17}. Given that the providers are not able to autonomously coordinate and decide who should serve a client's request, the decision logic is shared with the client's device, so that the best alternative can be selected every time.

In this paper, we propose a unified model for the realization of the mobile-edge-cloud continuum. At its heart, we propose A3-E, a protocol for the automated management of a software service's life-cycle. A3-E takes its name from its four main phases: \textit{(A)wareness, (A)cquisition, (A)llocation} and \textit{(E)ngagement}. First of all, A3-E enables mutual client-provider awareness that allows for the opportunistic and context-dependent placement of services along the continuum. Second, the model extends the Functions-as-a-Service (FaaS) computing paradigm~\cite{Hendrickson:2016,baldini2017serverless,GarrigaMendonca2017} to allow stateless functions to be autonomously fetched, deployed and exposed --as microservices-- by a provider. 


In this paper we also present a prototype implementation of the proposed \textit{model}. The prototype is distributed across the continuum, and conceptually divided into two parts: one is responsible for the autonomous management of service life-cycles (provider-side), while the other is responsible for handling application requests and forwarding them to the provider that can best satisfy the client's requirements.

%In this paper we also present a \textit{client-side middleware} and a \textit{provider-side middleware} that help realize the \textit{A3-E model}. The former is responsible for handling application requests and forwarding them to the provider that can best satisfy the client's requirements; while the latter facilitates the development and provisioning of self-managed service life-cycles. 

%TODO review according to the actions taken after the 1st review
A3-E has been evaluated in the context of an Augmented Reality application. Thanks to A3-E the application was able to autonomously proxy its requests to services that were dynamically selected from a computing continuum. In our experiments the continuum was composed of a mobile runtime, two edge servers, and a cloud environment. The experiments show up to a $90$\% reduction of latency when edge services are used instead of cloud services, and a $74$\% decrease of battery consumption when computation is offloaded from the mobile device to edge/cloud servers. Moreover, by dynamically selecting what constituent to use in the continuum we were able to obtain 100\% availability; simultaneously we reduced the overall execution time, measured when only using the cloud; and the battery consumption, measured when only using the mobile runtime.

%TODO review according to the actions taken after the 1st review
The rest of this paper is organized as follows. Section~\ref{sec:example} discusses the challenges of developing applications in the continuum, and presents a running example scenario. Section~\ref{sec:proposal} provides a detailed description of the A3-E model, whereas Section~\ref{sec:implementation} details the implementation of client-side and server-side middlewares. Section~\ref{sec:evaluation} reports on the experiments performed to evaluate our proposal. Section~\ref{sec:related} presents related work. Finally, Section~\ref{sec:conclusions} concludes the paper and delineates future work.

