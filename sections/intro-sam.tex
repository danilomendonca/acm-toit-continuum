\section{Introduction}
\label{sec:intro}

Mobile devices, edge-, and cloud-computing have the potential to form a \textit{computing continuum} on which new and disruptive types of applications can be built. This continuum enables the seamless convergence of heterogeneous infrastructure, stretching all the way from cloud resources to mobile devices, including intermediate steps such as ISP gateways, cellular base stations, and private cloud deployments.

The heterogeneity of the computing continuum is profound and multi-faceted. In the cloud, computing resources are typically provided through virtualization and containerization~\cite{leitner2016patterns, Quatrocchi2016discrete}, and there is an illusion of infinite resource availability thanks to horizontal scaling. In contrast, in edge computing, computational resources are scarce and must be managed very efficiently~\cite{Shi:2016, GarrigaMendonca2017}. This is even truer for mobile devices, as they are strongly constrained by battery and other limitations. 

In the cloud, networking protocols and technologies (e.g., traffic managers, DNS, etc.) allow clients to access resources across countries and continents. Conversely, in edge computing, to access resources they must be available within the client's network coverage, be it cellular (e.g., 5G) or local (e.g., domestic or office). Of course, we can consider the computational resources of the client's mobile device to be always accessible. % as long as the battery lasts.

Targeting availability but also efficiency and scalability, the decision of where in the continuum a specific calculation should be performed must be opportunistic, taking into account the resources that are actually available in the continuum at that specific moment in time, depend on the client's geo-location and connectivity, and be informed by existing QoS requirements, e.g., maximum acceptable latency. Given that distinct providers are not able to autonomously coordinate and decide who should serve a client's request, the decision logic is shared with the client's device, so that the best alternative can be selected every time.

Finally, there are other important QoS considerations that need to be made. While the cloud can provide vast computing power through elasticity, accessing these resources may involve multiple hops of network communication, leading to prohibitive latency in the processing of client requests. Indeed, one of the main motivations for introducing edge computation is to mitigate the network latency~\cite{Shi:2016}, which is nullified when execution is performed locally on the client's mobile device.

In this paper, we propose a unified model for the realization of the mobile-edge-cloud continuum. At its heart lays A3-E, a model for the efficient and scalable management of continuum service's life-cycle. A3-E takes its name from its four main activities: \textit{(A)wareness, (A)cquisition, (A)llocation} and \textit{(E)ngagement}. 

First of all, A3-E extends the Functions-as-a-Service (FaaS) computing paradigm~\cite{Hendrickson:2016,baldini2017serverless,GarrigaMendonca2017} to allow stateless and lightweight functions to be autonomously fetched, deployed and exposed --as microservices-- by heterogeneous providers. Second, the model enables mutual client-provider awareness that allows for the opportunistic and context-dependent placement of continuum microservices along the continuum. 

%TODO [Danilo] the way it is presented it seems the prototype implements mechanisms that have not been defined in the model. The responsibility of the domain manager and mobile middleware are defined by the model, thus it suffices to say that a prototype of both is presented and move the mechanism description to the introduction of the model itself in the previous paragraph(s)
The feasibility of A3-E has been demonstrated with an implementation of the proposed model. Also, A3-E has been evaluated in the context of an Augmented Reality application. Thanks to A3-E the application was able to autonomously proxy its requests to services that were dynamically deployed to and selected from a computing continuum. 

%In our experiments, the continuum was composed of a mobile runtime, two edge servers, and a cloud environment. The experiments 
The performed experiments show up to a $90$\% reduction of latency when edge services are used instead of cloud services, and a $74$\% decrease of battery consumption when computation is offloaded from the mobile device to edge/cloud servers. Moreover, by dynamically selecting what constituent to use in the continuum formed by mobile device, edge, and cloud, we were able to obtain 100\% availability; simultaneously we reduced the overall execution time, measured when only using the cloud; and the battery consumption, measured when only using the mobile runtime. Finally, compared to a similar approach for resource management of edge nodes, deployment time was up to 70\% lower with A3-E.



%The implementation is distributed across the continuum, and conceptually divided into two parts: one is responsible for the autonomous management of service life-cycles (provider-side), while a mobile middleware is responsible for handling application requests and forwarding them to the provider that can best satisfy the client's requirements.

%In this paper we also present a \textit{client-side middleware} and a \textit{provider-side middleware} that help realize the \textit{A3-E model}. The former is responsible for handling application requests and forwarding them to the provider that can best satisfy the client's requirements; while the latter facilitates the development and provisioning of self-managed service life-cycles. 




%TODO review according to the actions taken after the 1st review
The rest of this paper is organized as follows. Section~\ref{sec:continuum} presents the continuum model, formulates on the life-cycle management problem addressed by A3-E, and motivates our approach with a running example.
%discusses the challenges of developing applications in the continuum with a running example scenario. 
Section~\ref{sec:A3-E} provides a detailed description of the A3-E model, whereas Section~\ref{sec:implementation} details an implementation of A3-E from both provider's and client's viewpoints. Section~\ref{sec:evaluation} reports on the experiments performed to evaluate our proposal. Section~\ref{sec:related} presents related work. Finally, Section~\ref{sec:conclusions} concludes the paper and delineates future work.

