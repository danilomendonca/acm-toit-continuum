\section{Introduction}
\label{sec:intro}

Mobile devices, edge-, and cloud-computing have the potential to form a \textit{computing continuum} on which new and disruptive types of applications can be built. This continuum enables the 
%seamless [Danilo] saving sapce
convergence of heterogeneous infrastructure, stretching all the way from cloud
%resources [Danilo] saving sapce
to mobile devices, including intermediate steps such as ISP gateways, cellular base stations, and private cloud deployments.

%TODO check for additional EDGE citations 
The heterogeneity of the computing continuum is profound and multi-faceted. In the cloud, computing resources are typically provided through virtualization and containerization~\cite{leitner2016patterns, Quatrocchi2016discrete}, and there is an illusion of infinite resource availability thanks to horizontal scaling. In contrast, in edge computing, computational resources are scarce and must be managed very efficiently~\cite{Shi:2016, GarrigaMendonca2017}. This is even truer for mobile devices, as they are strongly constrained by battery and other limitations. 

%In the cloud, networking protocols and technologies (e.g., traffic managers, DNS, etc.) allow clients to access resources across countries and continents. Conversely, in edge computing, to access resources they must be available within the client's network coverage, be it cellular (e.g., 5G) or local (e.g., domestic or office). Of course, we can consider the computational resources of the client's mobile device to be always accessible. % as long as the battery lasts.

%Targeting availability but also efficiency and scalability, the decision of where in the continuum a specific calculation should be performed must be opportunistic, taking into account the resources that are actually available in the continuum at that specific moment in time, depend on the client's geo-location and connectivity, and be informed by existing QoS requirements, e.g., maximum acceptable latency. Given that distinct providers are not able to autonomously coordinate and decide who should serve a client's request, the decision logic is shared with the client's device, so that the best alternative can be selected every time.

Cloud resources are accessible by clients across countries and continents; conversely, in edge computing, a client access resources that are under the same network coverage, be it cellular (e.g., 5G) or local (e.g., domestic or office). On the other hand, we can consider the computational resources of the client's mobile device to be always accessible, as long as it has battery. While the cloud can provide vast computing power through elasticity, accessing these resources may involve multiple hops of network communication, leading to prohibitive latency in the processing of client requests. Indeed, one of the main motivations for introducing edge computation is to mitigate the network latency~\cite{Shi:2016}.
%TODO this sentence here makes no sense, since the local execution is dismissed due to battery drain [Martin]
%, which is even nullified when execution is performed locally on the client's mobile device.

In this paper, we propose A3-E, a unified model for the realization of the mobile-edge-cloud continuum. A3-E takes its name from its four main activities: \textit{(A)wareness, (A)cquisition, (A)llocation} and \textit{(E)ngagement}. The proposed model exploits the Functions-as-a-Service (FaaS) computing paradigm~\cite{Hendrickson:2016,baldini2017serverless,GarrigaMendonca2017} to allow stateless and lightweight functions to be autonomously fetched, deployed and exposed --as microservices-- by heterogeneous providers. 

A3-E conciliates providers goals and client applications needs with the efficient and scalable management of continuum microservices' life-cycles. Since distinct providers and infrastructures will not be able to autonomously coordinate and decide who should serve a client's request, A3-E enables a mutual client-provider awareness that allows for the opportunistic and context-dependent placement of microservices along the continuum.

The feasibility of A3-E has been demonstrated with an implementation of the proposed model. Also, A3-E has been evaluated in the context of an Augmented Reality application. Thanks to A3-E the application was able to autonomously proxy its requests to services that were dynamically deployed to a computing continuum. 

%In our experiments, the continuum was composed of a mobile runtime, two edge servers, and a cloud environment. The experiments 

The performed experiments show up to a $90$\% reduction of latency when edge replaced cloud, and a $74$\% decrease of battery consumption when computation is offloaded 
%from the mobile device 
to edge/cloud servers. Moreover, by dynamically selecting what constituent to use in the continuum in different contexts, 
%which includes the mobile device own resources, 
A3-E was able to maximize availability and prevent service interruptions, while reducing the overall execution time and battery consumption. Finally, A3-E reduced deployment time up to 70\%, compared to a similar approach~\cite{wang2017enorm} for resource management of edge nodes.


%The performed experiments show up to a $90$\% latency reduction when edge services are used instead of cloud services, and a $74$\% decrease of battery consumption when computation is offloaded from the mobile device to edge/cloud servers. Moreover, we obtained 93\% availability by dynamically selecting between cloud and edge servers, and 100\% when also considering the mobile device for computation (when remote services are not available). Simultaneously, we reduced the overall execution time by using the continuum, compared to using the cloud only. Finally, A3-E reduced deployment time up to 70\%, compared to a state-of-the-art approach for resource management of edge nodes.




%The implementation is distributed across the continuum, and conceptually divided into two parts: one is responsible for the autonomous management of service life-cycles (provider-side), while a mobile middleware is responsible for handling application requests and forwarding them to the provider that can best satisfy the client's requirements.

%In this paper we also present a \textit{client-side middleware} and a \textit{provider-side middleware} that help realize the \textit{A3-E model}. The former is responsible for handling application requests and forwarding them to the provider that can best satisfy the client's requirements; while the latter facilitates the development and provisioning of self-managed service life-cycles. 




%TODO review according to the actions taken after the 1st review
The rest of this paper is organized as follows. Section~\ref{sec:continuum} presents the continuum terms of infrastructure and application models, formulates on the life-cycle management problem addressed by A3-E, and motivates our approach with a running example.
%discusses the challenges of developing applications in the continuum with a running example scenario. 
Section~\ref{sec:A3-E} provides a detailed description of the A3-E model, whereas Section~\ref{sec:implementation} details an implementation of A3-E from both provider's and client's viewpoints. Section~\ref{sec:evaluation} reports on the experiments performed to evaluate our proposal. Section~\ref{sec:related} presents related work. Finally, Section~\ref{sec:conclusions} concludes the paper and delineates future work.

