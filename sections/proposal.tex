\section{A3-E}\label{sec:A3-E}

%First and foremost, A3-E's main objective is to enable the efficient and scalable placement of $\mu$-services along the continuum. In A3-E, clients and providers autonomously interact and decide for the placement of services according to the context. Moreover,  

To address the realization of the compute continuum, we propose A3-E
, a model supporting the self-management of continuum $\mu$-service life-cycle. A3-E inherits its name from its four main activities -- namely, \textit{(\textbf{A}wareness), (\textbf{A})cquisition, (\textbf{A})llocation, and (\textbf{E})ngagement}. 

A3-E targets the efficient and scalable placement of $\mu$-services along the continuum. For this, clients and distinct providers (domains) take part in the \textit{automated} and \textit{decentralized} runtime decision of which continuum resources --- among those of mobile, edge, and cloud --- should be employed in the provisioning of each $\mu$-services required by continuum applications.

%As an outcome of the first three activities, an instance of the service(s) required by the continuum application shall be ready for been engaged.

A3-E activities are illustrated in Fig.~\ref{fig:A3-E-process}. Each main activity 
is further refined by specific activities carried out by a \textit{domain manager} and by a \textit{mobile middleware}. These activities addresses different concerns in the interaction between client applications and service providers. Activities from both sides coordinate through signals (dashed arrows) and events (solid arrows). To address the intrinsic heterogeneity of the continuum, A3-E is flexible with respect to which activities are employed and how.
%For each phase, the main activities of a \textit{domain} and a \textit{client} are depicted along with their mutual relative state at the moment the phase starts: for a domain, a service state ranges from \textit{Free} to \textit{Allocated}, whilst a domain state ranges from \textit{Away} to \textit{Selected} for a client. 
%More precisely, Fig.~\ref{fig:A3-E-process} refers to the activities and states (in parenthesis) of a single client-domain interaction.

Next, we detail each main activity in A3-E, starting from the most general one, i.e., the one that applies to all types of client-domain interaction, and moving towards the more specific ones.

\begin{figure}[tbp]
	\includegraphics[width=1\textwidth]{figs/A3-E-process}
	\caption{A3-E overview. Each main activity is refined by specific Domain Manager and Mobile Middleware activities. Signals (dashed) and events (solid) triggered and handled by each activity are respectively depicted by leaving and arriving arrows.}
	\label{fig:A3-E-process}
\end{figure}

%\subsection{A3-E Process: Phases}\label{sec:A3-E-process}

%Next, the four A3-E phases are further described and mapped to the requirements elicited in  Section~\ref{sec:requirements}. Later on, other possible instances of the A3-E model are correlated with scenarios of the compute continuum.

\subsection{Engagement}\label{sec:A3-E-engagement}

A3-E's \textit{Engagement} models the actual provisioning of a continuum $\mu$-service after its successful allocation.
%: at the beginning of this phase, the continuum $\mu$-service has been \textit{allocated} by a domain, which in turn has been previously \textit{selected} by the client. 
Throughout this activity and as long as the client-domain relation persists, the client is able to engage with that domain by means of invocations to the provided $\mu$-service. 

Remote domains (i.e., cloud and edge) are engaged through distributed protocols (e.g., through HTTP requests or WebSockets). To enforce a common interface between the mobile middleware and heterogeneous domains, the mobile domain should also expose its functionality as local services decoupled from the client application.

During Engagement, the domain manager deals with the following events:

\begin{itemize}
	
	\item \textbf{$\mu$-service deallocated:} indicates the unavailability of a given $\mu$-service. The manager must react by queuing subsequent requests for that service.
		
	\item \textbf{$\mu$-service allocated:} indicates the availability of a given $\mu$-service. The manager must react by resuming the processing of pending and subsequent requests.	

	\item \textbf{$\mu$-service requested:} indicates the arrival of a request for a specific $\mu$-service. The manager must handle the event with the allocation of the request to a service instance after a \textit{load balancing} strategy.
\end{itemize}

In turn, the mobile middleware deals with the following events:

\begin{itemize}
	
	\item \textbf{C-Request arrived:} indicates the client application has sent a new request to the continuum. The event contains the target $\mu$-service reference along with any parameters. The middleware must handle it by invoking the corresponding $\mu$-service from the currently selected domain.
	
	\item \textbf{Response served:} indicates the arrival of a response from a domain for an invoked service. The middleware must handle it with the triggering of a \textit{C-Request served} event to be handled by the client application.
	
	%\item \textbf{C-Request served:} indicates a given C-request has been processed. It contains the original $\mu$-service reference along with any return value(s). The client application is responsible for handling the event.
	
	\item \textbf{Domain absent:} indicates no domain is currently available for that specific service. The middleware must react by queuing subsequent C-requests and, in case of latency violation, triggering a \textit{C-request failed} event.
	
	\item \textbf{Domain changed:} indicates a domain have been selected for a specific $\mu$-service. The middleware must handle it by resuming the forward of any queued and subsequent C-requests.
	
\end{itemize}

%TODO [Danilo] requirements must be passed by the application before, otherwise the domain selection would need to happen after the request has been fired
%It also contains continuum requirements that must be taken into account by the middleware in the decision of which 

%Two types of event dictate the end of an engagement: i) the client makes no further requests after a time interval; ii) the client selects another domain; and iii) the domain manager requires the deallocation of the service instance. 

%In all three cases, resources become available in the domain. In the latter case, the client is forced to select another domain.


%In this phase the request has already been provisioned by one or more domains and the client-side middleware (CSM) has already selected a specific domain to make the request. 

%handled and parsed by the client-side middleware (CSM), and . 


%Also, one or more domains must have setup and allocated the requested service for execution and the CSM must have selected a specific domain among all providing the same service. Finally, client's request are sent, processed, received, and returned to the application.

%Current FaaS providers allow functions to be exposed as REST services. The same applies to open source platforms implementing the FaaS model. Finally, different approaches may be used to expose local computation as services in mobile platforms like Android and iOS.

%As an exception, computation provided by mobile devices can be accessed by means of local calls to functions executed by the mobile platform.

\subsection{Allocation}\label{sec:A3-E-allocation}

%\begin{figure}[thbp]
%	\centering
%	\captionsetup[subfigure]{width=0.4\textwidth}	
%	\null\hfill
%	\subfloat[Domain $\mu$-services allocation control loop; domains must monitor the QoS of deployed $\mu$-services and adapt its allocation scheme to prevent SLA violations.\label{fig:service-allocation-loop}]{ \includegraphics[width=0.4\textwidth]{figs/service-allocation-loop}}
%	\captionsetup[subfigure]{width=0.4\textwidth}	
%	\hfill
%	\subfloat[Per $\mu$-service domain selection control loop; clients monitor $\mu$-services from available domains and select the one that best satisfies its requirements.\label{fig:domain-selection-loop}] {\includegraphics[width=0.4\textwidth]{figs/domain-selection-loop}}
%	\hfill\null
%	\caption{Self-management loops for domain-side $\mu$-services allocation and client-side domain selection}\label{fig:allocation-loops}
%\end{figure}


%TODO we may change placement for allocation to avoid confusion with the placement among different edge servers (e.g., in the context NFV)
The \textit{Allocation} models the deployment of continuum $\mu$-services on a pool of resources from cloud and edge providers (assuming $\mu$-services from mobile domains are pre-allocated). It also captures the client-side selection of providers for each of the $\mu$-service employed by the application.

%From the domain's perspective, the allocation phase models the placement of $\mu$-services on the domain's resources, i.e., on its pool of servers, virtual machines, and containers. At the beginning of this phase, $\mu$-service artifacts have been \textit{acquired} by the domain, and the client has been \textit{notified} of this.

The scope of the provider-side allocation is limited by its domain boundaries. For example, cloud domains allocate $\mu$-services to containers in resourceful datacenters covering a large area. On the other hand, edge domains rely on containers from one or more (virtual) machines covering a an office or a building (local-edge) or a 5G base station area (mobile-edge).

To realize this activity, the domain manager exploits a self-management loop~\cite{kephart2003vision} (see Sec.~\ref{sec:ps_allocation}) to guarantee a specified QoS by dynamically allocating resources (i.e., containers) to continuum $\mu$-services. Throughout Allocation, the domain manager deals with the following events:

\begin{itemize}
	
	\item \textbf{$\mu$-service acquired:} indicates that function(s) and dependencies have been fetched and the $\mu$-service is ready to be deployed. The domain manager must react by including this $\mu$-service in its self-management loop.
	
	%\item \textbf{New client:} indicates the arrival of a new client of a given $\mu$-service. 
	
	\item \textbf{$\mu$-service requested}: as defined in Section~\ref{sec:A3-E-engagement}. The domain manager must take this event into account as part of its self-management loop.
	
\end{itemize}


%Traditionally, cloud domains employ automated scaling mechanisms in which virtual machines and container instances are (de)allocated on demand. More recently, cloud-based FaaS platforms (e.g., Amazon Lambda, Google Cloud Functions) extend these mechanisms to stateless functions. The later represent an extreme type of allocation in which no pre-allocation of resources is needed and functions are executed by a shared runtime platform. 

%To realize this activity, the domain manager exploits a self-management control loop~\cite{kephart2003vision} (see Figure~\ref{fig:service-allocation-loop}) in which the $\mu$-services are instantiated according to: (i) a monitored QoS (e.g., the latency with each domain), (ii) a SLA, and (iii) the availability of the computational resources. 
%Once , the DSM informs the client whether the $\mu$-services can be considered ``acquired'' or not.
%For instance, in a centralized implementation, the DSM orchestrates the placement of functions to containers distributed along multiple servers.


%TODO the SLA part is too vague, we must be more assertive regarding priority
%While in cloud domains scalability is virtually unlimited, in finely distributed edge domains scalability needs to be prioritized to favor applications with more demanding requirements. For instance, edge providers could support two types of SLAs: one for critical applications requiring high availability, and another for non-critical applications that may cope with lower degrees of availability.  

%The first type could be achieved with the pre-allocation of resources to these services, whilst the latter could rely on the opportunistic allocation of services upon demand and availability of resources. 
%In the scenario introduced in Section~\ref{sec:continuum}, the AV application should have a higher priority with respect to non-critical applications such as AR applications for tourists~\cite{GarrigaMendonca2017}. In this case the edge $\mu$-services might become unavailable to the AR applications, for example during rush hour. In that case the AR and other low-priority applications would have to rely on $\mu$-services being run in the mobile domain, or in a cloud domain.

%The specific algorithms for the placement of services among the domain's resources that should be employed at the analysis phase are out of the scope of this paper. Nonetheless, recent works~\cite{} have addressed this challenge in the context of a continuum formed by edge and cloud datacenters. 

%Given the state of different domains perceived by a client, the mobile middleware must decide which domain is responsible for each $\mu$-service consumed by the application. 

A self-management loop (see Sec.~\ref{sec:cs_allocation}) is also exploited by the mobile middleware in the selection of the domain alternative that best satisfies the client's needs. For each $\mu-service$ consumed by the client application, the middleware checks the corresponding QoS levels from the list of capable domains. %A multi-attribute analysis then decides for the best alternative satisfying the application requirements.
Throughout Allocation, the mobile middleware deals with the following events:

\begin{itemize}
	
	\item \textbf{Domain acquired:} indicates the agreement of a domain in providing a given $\mu$-service. The mobile middleware must react by including this domain in its self-management loop.	
	
	\item \textbf{Domain lost:} indicates a domain can no longer provide a given $\mu$-service. The mobile middleware must react by removing this domain from its self-management loop.
	
\end{itemize}



%, i.e., it models the computation placement along the client's perception of the continuum. 
%This decision should consider a list of available domains providing services requested by the client application with accompanying QoS attributes. Accordingly, whereas the domains should take care of intra-domain allocation through service placement, the clients are responsible for the inter-domain allocation through service selection.

%Analogously to the domain-side, the CSM manages allocation with a self-management loop , this time by checking QoS levels of services from each available domain and deciding for the alternative that best satisfies the client's requirements. 

%This sub-process is the main client-side activity required for the realization of the continuum, as it allows clients to seamlessly alternate among different continuum domains according to the context. 

%TODO [Danilo] check the consistency of the usage of the running example in this Section
%If we go back to our running example, in the absence of appropriate edge domains, the low-priority AR applications would need to choose between their local mobile domain and the cloud domain. If the application's requirements favor low-battery consumption, the cloud domain will be chosen for allocation. Otherwise, if low latency is the most important QoS metric, the local mobile domain will be chosen. As the number of requirements grows, a multi-objective optimization algorithm may be employed to decide among alternative domains.


%, upon unavailability of edge domains providing services with low latency, the AR application previously introduced would have to choose among mobile or cloud domain. If the application requirements prioritizes low battery consumption (e.g., because battery level is low), it should opt for the cloud domain. Otherwise, if low latency is the priority requirement, it should opt for the cloud domain. 



%The allocation phase has the following purposes: 1) to enable the efficient (Req. \textbf{R1.1}) and automated (Req. \textbf{R3.1}) allocation of domains' computational resources; and to enable clients to choose the best candidate among different available domains (Req. \textbf{R2.1}).


\subsection{Acquisition}\label{sec:A3-E-acquisition}

The \textit{Acquisition} models the automated download and installation of continuum $\mu$-service artifacts and the confirmation of the domain's capability in providing that $\mu$-service.

%From the domain's perspective, the acquisition phase models the dynamic and automated acquisition of the $\mu$-service artifacts needed during the allocation phase. 
%In particular, artifacts refer to: (i) the function(s) composing the service (e.g., a Java compiled class); (ii) static data (e.g., a trained neural network model); and (iii) other dependencies (e.g., software libraries).
%upon identification of requirements from a given application. 
The ultimate goal of Acquisition is to mitigate the use of domain resources before the $\mu$-service is actually needed, while also facilitating IT operations (Ops) for developers and administrators. 

%At its beginning, a domain has already \textit{identified} the $\mu$-service required by the client, which in turn is \textit{aware} of that domain's existence.

Ops mitigation is particularly important in finely distributed edge domains, since the manual administration of a large number of $\mu$-services can prove cumbersome and expensive. Nevertheless, this can also prove useful for cloud domains. Indeed, to the best of our knowledge, current FaaS platforms only support uploading (pushing) functions through public interfaces. 

The acquisition of functions would be managed by a process within the domain, therefore allowing $\mu$-services to be downloaded (e.g., pulled from a repository) and installed on demand. Note that mobile domains are exempt of performing the allocation phase as local service artifacts are assumed to be downloaded and installed along with the client application.

% In addition to function sources, artifacts may comprise data and libraries needed by the service.

Throughout Acquisition, the domain manager handles the following event:

\begin{itemize}
	
	\item \textbf{$\mu$-service identified:} indicates the request for deployment of a new $\mu$-service. The manager must proceed with the verification of requirements and the triggering of a \textit{service acquired} (or \textit{denied}) event according to its capability in providing that $\mu$-service.
	
\end{itemize}

%In this phase, the domain manager receives a set of application requirements from the client's CSM, namely the list of $\mu$-services and the URL of their repositories. The desired $\mu$-service artifacts are then downloaded and installed, at which point the DSM informs the client whether the $\mu$-services can be considered ``acquired'' or not. 
%Throughout the $\mu$-services' life-cycles, the DSM periodically checks for new versions of acquired services and updates them accordingly. 
%As an example, the services consumed by both AR applications introduced early can be autonomously acquired on demand by the local-edge servers in the user's office and home, preventing the company and the user to perform such operation. 
%In case the service has already been acquired or as the acquisition finishes, clients should add that domain to their list of available domains. 

From the client's perspective, the Acquisition corresponds to the addition of a domain to a list of capable domains. %This is done once the domain has proven that it can actually provide the requested $\mu$-service. 
During this activity, the mobile middleware deals with the following events:

\begin{itemize}
	
	\item \textbf{Domain found:} indicates a potential domain for a $\mu$-service has been found. The middleware must proceed with the $\mu$-service identification.	
	
	\item \textbf{Domain acquired:} indicates a successful acquisition of a previously identified $\mu$-service. The middleware must react with the triggering of a \textit{domain confirmed} event.
	
	\item \textbf{Domain denied:} indicates the failure in acquiring and/or deploying a $\mu$-service. The middleware must proceed with the blacklisting of that domain. 
	
\end{itemize}


 %follow the identification of the domain's capability in providing the requested service. This phase is realized by the CSM with the following sub-process: the CSM should expect a confirmation from the DSM regarding its compliance in providing the service required by the application. Once confirmed, the CSM adds that domain to a list of available domains used by the client-side allocation phase. 

%As an example, a real-time translation application from/to streams of different spoken languages require services with low-latency. The translation can either rely on local services provided by the mobile domain (zero network latency) or on remote services provided by the edge domain (low network latency). Given the battery constraints of the mobile device, edge services are preferred. Instead of having all artifacts pre-installed, the edge's DSM acquires the data and codebase from a repository informed by the CSM upon detection of the user in its coverage area. The setup process takes no more than a minute, during which local services were consumed. Once the setup is ready, the application can start streaming captured conversations to edge-based services, which in turn reply with a translated audio stream.

%From the domain-side, the lack of acquisition implies that service assets must be previously made available. Nonetheless, the preliminary acquisition of a large number of assets is limited by the domain storage capability. 

%Conversely, the automated and opportunistic acquisition of service assets improves storage efficiency with the cost of a setup time $\Delta_{AQ}$. For instance, domains that become aware of clients' requirements may pro-actively start the acquisition phase and become ready for allocation before the first service request arrives.

%otherwise, domains must rely on the detection of a first service request or some other triggering condition to start the acquisition phase and, after setup time $\Delta_A$, become ready for allocation. 


\subsection{Awareness}\label{sec:A3-E-awareness}

%Why do we need awareness?
%CA: awareness is not needed because the edge domain should always be coupled to the network infrastructure; network components shoudl aways route traffic to existing edge servers; additionally, the edge domain should be able to acquire and allocate $\mu$-services upon detection of the first requests.  
%A: A3-E model is agnostic w.r.t. the use of network technologies to route traffic to the edge servers; a given domain may count on network components to traffic route to its servers instead of negociating directly with clients aware of its existance; nonetheless, the lack of awareness limits the acquisition and deployment of services to reactive, as the domain would only identify a given service upon the first request has been made. Without awareness, clients would not be able to choose from alternative domains. 

From the provider's viewpoint, the awareness phase models the discovery of continuum applications in one of its domain's coverage area, indicating the imminent need for the corresponding $\mu$-services.

%Its main purpose is to enable domains to pro-actively initialize the Acquisition and Allocation activities, based on the awareness of devices in a domain's coverage area. 
Cloud-based FaaS platforms like AWS Lambda~\footnote{} adopt a cold start policy in which functions are allocated after their first call following a period of idleness. Taking advantage of the client awareness, the proposed mechanism has two benefits: (i) it alleviates the cold start by pro-actively allocating $\mu$-services just before they are needed; and (ii) it enables $\mu$-service Acquisition to be opportunistic.

Throughout Acquisition, the domain manager handles the following event:

\begin{itemize}
	
	\item \textbf{$\mu$-service identified:} indicates the request for deployment of a new $\mu$-service. The manager must proceed with the verification of requirements and the triggering of a \textit{service acquired} (or \textit{denied}) event according to its capability in providing that $\mu$-service.
	
\end{itemize}

TODO: add client-side awareness 

%It copes with the need for efficiency and scalability of finely distributed edge domains by allowing acquisition and/or allocation of services to happen just in time, i.e., just before the client application needs them.
%and enables not only functions to be allocated, but also acquired in an opportunistic fashion.
%The benefit lies in the anticipation of (opportunistic) services setup with respect to the arrival of the first service request, i.e., in the mitigation of service setup delay (also known as cold start). Since cloud domains cover a large area, the later do not employ the awareness phase. Needless to say, mobile domains do not require awareness for sharing the same platform with client applications.

%TODO [Danilo] Commented-out in favor of a more abstract description in terms of events, as broadcasting is something local-edge specific
%The DSM achieves this by broadcasting its existence and by waiting for clients to pass along their requirements. In our running example this occurs when the user's domestic local-edge server becomes aware of the new mobile game that the user had just installed. 
%%nd the discovery of client applications along with their requirements (i.e., services). The later are passed to the following phase of acquisition.
%%then receive all client application requirements (i.e., services) as soon as the client's mobile device enters the domain's coverage area, and then pro-actively starting acquisition and allocation. 
%%For example, in the real-time translation application previously introduced, the service setup delay was mitigated by having the acquisition of the data and codebase composing the service to start as soon as the user entered the edge domain's coverage area.
%%For example, the setup of services required by the mobile multiplayer game application by the user's local-edge server follows the awareness of a new application.
%From the client's perspective, the awareness phase models the discovery of domains, and corresponding $\mu$-services, whose network addresses are not previously known. In particular, it tackles edge domains that are integrated with the local network infrastructures of buildings and public spaces. This modality contrasts with cloud which are accessed through DNS and traffic managers. Needless to say, the awareness phase is not considered by mobile domains. The CSM intercepts the provider's broadcast messages, and reacts by sending back its application requirements. This process should happen once, and in a timely fashion, upon connection to new networks to mitigate battery consumption. As an example, the local-edge server in our user's home is discovered when her mobile device connects to her domestic Wi-Fi network. 


%Once the domain is ready, this domain becomes an alternative for the provisioning of services required by the many applications (e.g., the mobile multiplayer game) hosted by the user's smartphone, tablet, and/or other of his IoT gadgets. 


%Finally, the Awareness phase has the following purposes: 1) to enable domains to pro-actively initialize the acquisition and allocation phases based on its awareness of applications whose hosting devices happens to be in the domain coverage area (Req.~\textbf{R2.3}); and 2) to enable clients to discover the address of local domains (Req.~\textbf{R2.2}).

%From the domains perspective, the awareness of clients presence in their coverage area allows a proactive download and installation of services artifacts (acquisition phase) and/or the allocation of services (allocation phase) potentially before a first request to that service arrives, alleviating the delay introduced by services setup.  From the clients perspective, the awareness phase increases the range of alternatives from the continuum that can be used to satisfy their requirements.

%Such behavior allows that are opportunistically acquired and/or allocated to mitigate their setup delay by triggering these phases upon awareness of client(s) in their coverage area.

%From the domain-side, the lack of awareness of clients in the domain coverage area prevents triggering the acquisition and subsequently allocation phases based on this event. From the client-side, the lack of awareness from surrounding domains prevents them to make the decision of which domains to use. In the later case, clients must rely on external components to reach servers (e.g., traffic managers and DNS servers).

%\input{sections/policies}


%
%\subsection{Reference Architecture}
%
%\begin{figure}[tbp]
%	\includegraphics[width=.95\textwidth]{figs/A3-E-reference-architecture}
%	\caption{A3-E architecture in Mobile Devices and edge domains}
%	\label{fig:reference-architecture}
%	\end{figure}
	

\section{Implementation}

To demonstrate the feasibility of A3-E in managing the life-cycle of continuum applications, we describe the implementation of our model. Due to its complexness, we focus on the implementation of the self-management loops from both provider and client viewpoints.

\subsection{Control Theory-based $\mu$-Services Allocation}~\label{sec:ps_allocation}

To cope with the low-latency requirement of continuum applications and a highly dynamic workload  (e.g., from users that quickly enter and leave a particular edge area) we 
%TODO move to the problem formulation i) consider the \textit{response time} as the reference metric of QoS and ii) 
propose a fast and scalable materialization of the provider-side self-management loop based on control theory. In literature one can find many approaches of dynamic resource allocation based on heuristics~\cite{dustdar0}, artificial intelligence~\cite{ia1} and queue theory~\cite{queue1}. Nevertheless, we adopted an extremely lightweight control theoretical technique to fully exploit the container technology~\cite{Quatrocchi2016discrete}: compared to virtual machines containers can be booted in few seconds, therefore we used controllers that are able to change the resource allocation with a very fast period (i.e., in the order of few seconds).

Figure~\ref{fig:A3Edomain-manager} depicts an overview of the control system, which is responsible for the deployment of containers to the cluster of (virtual) machines composing a domain's pool of resources (or the \textit{plant} in control-theoretical terms). Each container provides the runtime environment required for the execution of a given continuum $\mu$-service; and multiple instances of $\mu$-services may coexist in one or more machines (horizontal scalability).

\begin{figure}[tbp]
\includegraphics[width=0.7\textwidth]{figs/domain-manager-allocation}
\caption{Control loop implementing the self-management of a domain's resources}
\label{fig:A3Edomain-manager}
\end{figure}

%The system 
%to be controlled, or the \textit{plant} in control-theoretical terms, is the provider's resource %pool composed by a cluster of (virtual) machines. 

%Containers are deployed in those machines and they execute $\mu$-services. Each service can be replicated on different machines, enabling horizontal scalability. 

The control plant is subject to different signals that could be measurable (input variables) or unknown (disturbances). Considering a discrete time, for each $\mu$-services $s_i \in S$ we define $\lambda_i(t)$ as the function of the measured arrival rate of requests at each control time $t$.
; while $\bar{\lambda}(t)$ is the corresponding vector for all $s_i \in S$. 
%TODO c(t) is the same as f_{i,j}(t) and \bar{c}(t) is the same as  F_{i}. 
At time $t$ each $\mu$-service $s_i \in S$ is executed in a $c_i(t)$ number of allocated containers, while $\bar{c}(t)$ is the corresponding vector for all $s_i \in S$. The disturbances are defined as $\bar{d}$ and cannot be directly controlled and measured by definition. Finally, $\bar{\tau}$ is the system output and corresponds to the vector of response times of each $\mu$-service; while $\bar{\tau}^\circ$ corresponds to the vector of desired response times or control set-point (according to the SLA of each $\mu$-service). 

In our current setup the function $\bar{\tau}^\circ(k)$ does not vary over time, meaning a constant QoS for each  $\mu$-service. Of course, these values should be set below the thresholds defined in the SLA (i.e., ${\tau}^\circ_i(t) < \Delta_i, \forall i, x$ with $ 1 \le i \le m \wedge x \ge 0$). Moreover, since response time cannot be measured instantaneously but by aggregating the execution times of different requests over a predefined time window, many aggregation functions could be used without any change to the system model and controller. For example in our current setup we are using the $99th$ percentile function. 

We dedicate one controller per $\mu$-service with the goal to compute the next container allocation in order to obtain:
\begin{equation}
\tau(k)^\circ - \tau(k) = e(k) = 0\quad \forall{k} \ge 0
\end{equation}
or more realistically, considering all the services:
\begin{equation}
\bar{e}(k) \simeq 0 \quad \forall{k} \ge 0
\end{equation}
To do that the controllers must model the system with enough details to govern the dynamics of the plant. In control theory this is done by defining a characteristic function. We assume that this function does not need to be linear but regular enough be linearizable in the domain space of interest. Moreover, we consider this function to be dependent on the ratio of the number of allocated containers $c$ and the request rate $\lambda$.  This function, $f$ to give it a name, is intuitively monotonically decreasing towards a possible lower horizontal asymptote, as it can be assumed that once the parallelism degree of a $\mu$-service is fulfilled by the available containers, adding new ones causes no further decrease in the response time. More specifically, we found a practically acceptable function to be
\begin{equation}
f \left( \frac{c(k)}{\lambda(k)}\right)  = \widetilde{u}(k) = c_1+\frac{c_2}{1+c_3\frac{c(k)}{\lambda(k)}}
\label{eqn:CsysModel-f}
\end{equation}
\noindent where parameters $c_1$, $c_2$, and $c_3$ were obtained through profiling of each $\mu$-service. Thus we obtain the following dynamic system:
\begin{equation}
\tau(k)  = p \tau(k-1) + (1-p)\widetilde{u}(k-1)
\label{eqn:CsysModel-s}
\end{equation}
where $p \in [0,1)$ is the single pole of the system estimated with step response analysis. As control techniques we rely on PI controllers because they are able to effectively control systems dominated by a first order dynamic ~\cite{aastrom1995pid} (i.e., representable with first order differential equations) such as the studied ones. PI controllers compute the next state of a plant by using two contributions: one that is proportional and another that is integral to the error $e$. Algorithmically: 
\begin{align*}
e   &:= \tau_r^{\circ}-\tau_r;\\
x_R &:= x_{R_p}+(1-p)*e_p;\\
c   &:= \lambda*f_{inv}((\alpha-1)/(p-1)*(x_R+e));\\
c   &:= max(min(Kmax,c), Kmin);\\
x_{R_p} &:= (p-1)/(\alpha-1)*f(c/\lambda)-e;\\
e_p  &:= e;
\end{align*}
where the ``$p$'' subscript denotes ``previous'' values, i.e., those corresponding to the previous step, while ``$f$'' and ``$f_{inv}$'' correspond to the characteristic function and its inverse, respectively, while $\alpha \in [0,1)$ is the single pole of the controller (the higher the value the faster will be the error convergence to $0$). The algorithm is run by each controller at each control step independently (i.e. without synchronization) to compute the next container allocation for the corresponding $\mu$-service. $\hat{c}$ is the vector containing the allocations of all the services. $\hat{c}$ is not immediately actuated (through the container manager of choice such as Docker Swarm~\cite{Swarm} or Kubernetes~\cite{Kubernetes}) since the sum of the allocations could be greater than the entire capacity of the resource pool. In fact $\hat{c}$  is passed to another control component called  \textit{ContentionManager}. The  output of ContentionManager is a vector $\bar{c}$, the actual container allocations of $\mu$-services, defined as 
\begin{equation}
\bar{c}(k) =
\begin{cases}
\hat{c}(k),& \text{if \textit{no resource contention}}\\
scaleDown(\hat{c}(k)),              & \text{otherwise}
\end{cases}
\label{eqn:CsysModel-SS}
\end{equation} 
where function $scaleDown$ scales down the allocations to be equal to the maximum capacity according to a priority policy. 
For example in the scenario introduced in Section~\ref{sub:example}, the AV application should have a higher priority with respect to non-critical applications such as AR applications for tourists~\cite{GarrigaMendonca2017}. In case of contention the edge $\mu$-services might become unavailable (or available with an higher response time) to the AR applications, for example during rush hour. In that case the AR and other low-priority applications could have to rely on $\mu$-services being run in the mobile domain, or in a cloud domain. Finally \textit{ContentionManager} updates the state of each controller (variable $x_{R_p}$) to reflect the actual allocation.

\subsection{Multi-Attribute Domain Selection}~\label{sec:cs_allocation}

%As described in Section~\ref{sec:proposal}, the CSM component interacts with DSM from different domains that could be either discoverable using a DNS-like mechanism or advertisement. 

The main goal of the client-side middleware\footnote{Documentation and source code are available at \url{https://github.com/deib-polimi/A3-E-CSM}} is to allow client applications to invoke A3-E microservices without knowing where they will actually be executed within the computing continuum: locally on the mobile domain, in a local-edge server, in a mobile-edge server, or in the cloud. Its selection algorithm is a multi-objective function that takes into account the measured QoS and the requirements. The provided implementation targets Android-based devices. However, it does not use Android-specific technology and can therefore be generalized to other mobile platforms. 

The provided implementation consists of components responsible for the Awareness phase (i.e., the discovery of domains and identification of requirements), the Acquisition phase (i.e., the update of a list of available domains following the DSM notification), and finally the set of  components responsible for Allocation phase, during which microservices selection occurs. The latter implement a self-managing control loop~\cite{kephart2003vision} which: (i) monitors microservices provided by different domains in terms of QoS metrics; (ii) analyzes the best alternative satisfying requirements of the client application; and (iii) updates the domain selection for a given microservice. In addition to A3-E's \textit{Location requirements}, the prototype considered two types of \textit{QoS requirements}:

\begin{enumerate}
	%	\item \textit{Location Requirement}s constrain where the microservice can be placed within the continuum, i.e., \textit{LOCAL}, \textit{LOCAL\_EDGE}, \textit{MOBILE\_EDGE}, or \textit{CLOUD} or a combination of the above; 
	
	
	\item a \textit{Latency Requirement} constrains network latency, i.e., \textit{ANY}, \textit{LOW} or \textit{VERY\_LOW}; and 
	
	
	\item a \textit{Computational Requirement} defines how relevant it is for a microservice to have fast computing, i.e., \textit{ANY}, \textit{FAST} or \textit{VERY\_ FAST}. 
\end{enumerate}

The latter is modeled as a fixed score ranging from $1$ to $5$\footnote{Labeling computational power is also common in the cloud where different tiers of virtual machines are available -- \url{https://aws.amazon.com/ec2/instance-types/}}. By default, the local domain has a score of $1$, the edge domains have a score of $4$, while the cloud domains have a score of $5$. Note that since the cloud provides the illusion of infinite scalability it gets the maximum score, regardless of the VMs that are actually being used. More sophisticated approaches with dynamic scores taking into account the saturation of the domain or the device's battery level (in the case of a mobile domain) are considered as future work.

\begin{algorithm}[thb]
	\caption{A3E Selection Algorithm}
	\label{alg:selection}
	\begin{algorithmic}[1]
		
		\Function{selectDomain}{A3EService $microservice$, A3EDomain[] $identifiedDomains$}
		\State$scoreRange \gets 5$
		\State $maxLatency \gets \Call{computeMaximumLatency}{identifiedDomains}$
		\State $maxCpuPower \gets \Call{computeMaximumComputationalPower}{identifiedDomains}$
		\State $latencyWeight \gets microservice.getLatencyRequirement()$ 
		\State $cpuPowerWeight \gets microservice.getComputationalPowerRequirement()$ 
		\State $maxScore \gets 0$
		\State $selectedDomain \gets null$
		\ForAll{$domain \in identifiedDomains$ } 
		\State $latency \gets domain.getLatency()$ 
		\State $cpuPower \gets microservice.getComputationalPower()$ 
		\State $latencyScore \gets latencyWeight*((scoreRange-1)*(1 - latency/maxLatency)+1)$ 
		\State $cpuPowerScore \gets cpuPowerWeight*(scoreRange*(cpuPower/maxCpuPower))$
		\State $score \gets (latencyScore + cpuPowerScore) / (latencyWeight + cpuPowerWeight)$
		\If{$score \geq maxScore$} 
		\State $maxScore \gets score$
		\State $selectedDomain \gets domain$
		\EndIf
		\EndFor 
		\State \Return $selectedDomain$
		\EndFunction
	\end{algorithmic}
\end{algorithm}



Algorithm~\ref{alg:selection} describes the procedure employed in the microservice selection. The algorithm computes a score ranging from $0$ to $5$ (line $2$). First, it retrieves the maximum computational power and network latency from available domains (line $3$ and $4$). Then, it retrieves the weights assigned to each QoS metric (lines $5$ and $6$). These weights correspond to the values associated to the \textit{LatencyRequirement} and \textit{ComputationalRequirement} of the microservice. The \textit{ANY} value corresponds to a weight of $0$, a latency requirement of \textit{LOW} and a computational power requirement of \textit{FAST} correspond to a weight equal to $1$, while a latency requirement of \textit{VERY\_LOW} and a computational power requirement of \textit{VERY\_FAST} correspond to a weight equal to $2$. For each domain, the algorithm computes the overall score (line $9$ to $14$). The latency score is computed by normalizing the value retrieved at line $10$ with the maximum latency previously computed. The normalized value ranges from $0$ to $1$, the higher this value is the higher the latency. Since a higher score should mean lower latencies, the algorithm computes the complement of this value and adds $1$ to avoid scores equal to $0$. The latency score is computed to be between $1$ and $5$, and multiplied by the microservice's latency weight (line $12$). The computational power score is computed by normalizing the domain computational power retrieved at line $11$ with the maximum value across the identified domains. Again, the score for this metric is computed to be between $1$ to $5$ and multiplied by its weight (line $13$). Finally, the overall score is the weighted average between the scores obtained by the domains for the two QoS metrics.

%Two considerations must be added for this algorithm. First, 
Algorithm~\ref{alg:selection} is an instantiation of the SMART decision process~\cite{Olson1996}, in which multiple competing QoS objectives are taken into account using the following formula:

\begin{equation}
Smart(c) = \frac{\sum_{i=1}^{n} QoSAtrribute_i(c)*weight_i}{\sum_{i=1}^{n}weight_i} \label{eq:smart}
\end{equation}

\noindent
where $c$ is a domain (see Figure~\ref{fig:domain-selection-loop}), the QoS attributes values are network latency and the computational processing time (thus $n$ is $2$), and their weights are represented by the aforementioned latency and computation requirements. Note that, when available, \textit{edge domains have the highest chances of being selected}, since they usually combine a low network latency and a medium-to-high computational power. Finally, each microservice is mapped to the domain that best satisfies its requirements.

Last but not least, during the \textit{Engagement} phase the CSM handles C-requests triggered by the client application for a specific microservice in the continuum and invokes the domain previously selected. Domains are bound to an invocation resolver: edge and cloud domains resolvers fire an HTTP request, while the resolver bound to a mobile domain will broadcast an Android event containing the request along with a callback. In particular, this broadcast is handled by the mobile domain DSM (see Sec.~\ref{sec:mobile-domain-DSM}).